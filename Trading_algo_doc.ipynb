{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a5ded63-809c-4088-bbc1-d5526add6ba2",
      "metadata": {
        "id": "9a5ded63-809c-4088-bbc1-d5526add6ba2"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:200%; font-weight:bold;\">\n",
        "Algorithmic Trading Assignment â€” Louis Delacour Lucas Moerlen\n",
        "</p>\n",
        "\n",
        "<p style=\"color:#4B0082; font-size:120%;\">\n",
        "In this assignment, we will explore how to find data, manage it, test algorithmic trading techniques, and plot our findings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x",
      "metadata": {
        "id": "x"
      },
    {
      "cell_type": "markdown",
      "id": "x",
      "metadata": {
        "id": "x"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "1. We will start by selecting our tickers, which we will retrieve using a web-scraping method directly from Wikipedia.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x",
      "metadata": {
        "id": "x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average\"\n",
        "tables = pd.read_html(url)\n",
        "\n",
        "dow_jones_table = None\n",
        "for table in tables:\n",
        "    if 'Symbol' in table.columns:\n",
        "        dow_jones_table = table\n",
        "        break\n",
        "\n",
        "if dow_jones_table is not None:\n",
        "    tickers = dow_jones_table['Symbol'].tolist()\n",
        "    print(\"Dow Jones Tickers:\", tickers)\n",
        "\n",
        "    tickers_df = pd.DataFrame(tickers, columns=['Ticker'])\n",
        "    tickers_df.to_csv('dow_jones_tickers.csv', index=False)\n",
        "    print(\"\\nTickers saved to 'dow_jones_tickers.csv'.\")\n",
        "else:\n",
        "    print(\"Unable to find the Dow Jones components table.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b68f89-4e8d-4f93-b4a1-1646108aa22e",
      "metadata": {
        "id": "d1b68f89-4e8d-4f93-b4a1-1646108aa22e"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "2. We will now retrieve this week's news related to the Dow Jones thanks to <code>gnews</code> API, which we will later use to perform sentiment analysis.\n",
        "</p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffa473cf-fd77-4cd3-8e99-25360492abf1",
      "metadata": {
        "id": "ffa473cf-fd77-4cd3-8e99-25360492abf1"
      },
      "outputs": [],
      "source": [
        "!pip install gnews\n",
        "!pip install textblob\n",
        "from gnews import GNews\n",
        "from textblob import TextBlob\n",
        "\n",
        "google_news = GNews(language='en', country='US', period='1d')\n",
        "\n",
        "news_results = google_news.get_news('finance USA')\n",
        "\n",
        "positive, negative, neutral = 0, 0, 0\n",
        "\n",
        "for article in news_results:\n",
        "    title = article['title']\n",
        "    analysis = TextBlob(title)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity > 0.1:\n",
        "        positive += 1\n",
        "    elif polarity < -0.1:\n",
        "        negative += 1\n",
        "    else:\n",
        "        neutral += 1\n",
        "\n",
        "    print(f\"{title} --> Polarity: {polarity:.2f}\")\n",
        "\n",
        "total = positive + negative + neutral\n",
        "print(f\"\\nResults on {total} news articles:\")\n",
        "print(f\"Positive: {positive}\")\n",
        "print(f\"Negative: {negative}\")\n",
        "print(f\"Neutral: {neutral}\")\n",
        "\n",
        "if neutral > (positive + negative):\n",
        "    print(\"\\nOverall Sentiment: NEUTRAL - no significant risk.\")\n",
        "elif positive > negative:\n",
        "    print(\"\\nOverall Sentiment: POSITIVE. ;)\")\n",
        "elif negative > positive:\n",
        "    print(\"\\nOverall Sentiment: NEGATIVE. :'(\")\n",
        "else:\n",
        "    print(\"\\nOverall Sentiment: NEUTRAL. -_-\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f26e2946-cc7f-4bfa-b376-6c34d0ecc4e5",
      "metadata": {
        "id": "f26e2946-cc7f-4bfa-b376-6c34d0ecc4e5"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "3. We will now retrieve the 30 Dow Jones tickers to compare their return and volatility, in order to select only 10 of them (since the APIs we will use are limited, we aim to avoid overloading them). For this, we will use <code>yfinance</code>.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38407a61-0c46-4137-9fdc-dc299d857044",
      "metadata": {
        "id": "38407a61-0c46-4137-9fdc-dc299d857044"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def get_user_input_dates():\n",
        "    start_date = input(\"Entrez la date de dÃ©but (format: YYYY-MM-DD) : \")\n",
        "    end_date = input(\"Entrez la date de fin (format: YYYY-MM-DD) : \")\n",
        "    return start_date, end_date\n",
        "\n",
        "df = pd.read_csv(\"dow_jones_tickers.csv\")\n",
        "\n",
        "tickers = df['Ticker'].tolist()\n",
        "\n",
        "start_date, end_date = get_user_input_dates()\n",
        "data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
        "\n",
        "returns_1m = data.pct_change(periods=21).iloc[-1] * 100\n",
        "returns_1y = data.pct_change(periods=252).iloc[-1] * 100\n",
        "\n",
        "volatility_1m = data.pct_change().rolling(window=21).std().iloc[-1] * 100\n",
        "volatility_1y = data.pct_change().rolling(window=252).std().iloc[-1] * 100\n",
        "\n",
        "returns_data = pd.DataFrame({\n",
        "    'Ticker': tickers,\n",
        "    '1 Month Return (%)': returns_1m,\n",
        "    '1 Year Return (%)': returns_1y\n",
        "})\n",
        "\n",
        "volatility_data = pd.DataFrame({\n",
        "    'Ticker': tickers,\n",
        "    '1 Month Volatility (%)': volatility_1m,\n",
        "    '1 Year Volatility (%)': volatility_1y\n",
        "})\n",
        "\n",
        "\n",
        "returns_data = returns_data.set_index('Ticker')\n",
        "volatility_data = volatility_data.set_index('Ticker')\n",
        "\n",
        "\n",
        "merged_df = pd.merge(returns_data, volatility_data, on='Ticker')\n",
        "\n",
        "top_10 = merged_df.sort_values(by=['1 Month Return (%)', '1 Year Return (%)'], ascending=False).head(10)\n",
        "\n",
        "top_10.to_csv('top_10_stocks.csv')\n",
        "print(\"Merged DataFrame:\\n\", merged_df)\n",
        "print(\"\\nTop 10 stocks based on return and volatility:\\n\", top_10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7660837-9095-49db-ba98-7e739d821b12",
      "metadata": {
        "id": "c7660837-9095-49db-ba98-7e739d821b12"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "4. We use the Stock Data and Alpha Vantage APIs to retrieve intraday data. We rely on both because if we exhaust the daily quota on one, we can switch to the other.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85052e36-668d-4ed5-a6cb-ec9be768deb1",
      "metadata": {
        "id": "85052e36-668d-4ed5-a6cb-ec9be768deb1"
      },
      "outputs": [],
      "source": [
        "from alpha_vantage.timeseries import TimeSeries\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "alpha_key = 'RRX41GFUX011BIA6'\n",
        "stockdata_key = 'JiAuPr73vF9qfjeFlWvM64oAjEV0wslO3GoPnOUw'\n",
        "\n",
        "tickers_df = pd.read_csv('top_10_stocks.csv')\n",
        "tickers = tickers_df['Ticker'].tolist()\n",
        "tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
        "\n",
        "ts = TimeSeries(key=alpha_key, output_format='pandas')\n",
        "\n",
        "def get_intraday_data_alpha(ticker):\n",
        "    try:\n",
        "        data, _ = ts.get_intraday(symbol=ticker, interval='60min', outputsize='compact')\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        if \"call frequency\" in str(e).lower():\n",
        "            raise RuntimeError(\"Alpha Vantage daily limit reached\")\n",
        "        print(f\"Alpha Vantage error for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_intraday_data_stockdata(ticker):\n",
        "    try:\n",
        "        url = f\"https://api.stockdata.org/v1/data/intraday?symbols={ticker}&interval=1h&api_token={stockdata_key}\"\n",
        "        response = requests.get(url)\n",
        "        json_data = response.json()\n",
        "\n",
        "        if 'data' not in json_data or not json_data['data']:\n",
        "            print(f\"No data returned from StockData for {ticker}\")\n",
        "            return None\n",
        "\n",
        "        df = pd.DataFrame(json_data['data'][0]['values'])\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        df.set_index('datetime', inplace=True)\n",
        "        df = df.sort_index()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"StockData error for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "all_data = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    print(f\"\\nFetching data for {ticker}...\")\n",
        "\n",
        "    try:\n",
        "        data = get_intraday_data_alpha(ticker)\n",
        "    except RuntimeError:\n",
        "        print(\"Alpha Vantage limit reached. Switching to StockData.org.\")\n",
        "        data = get_intraday_data_stockdata(ticker)\n",
        "\n",
        "    if data is not None:\n",
        "        all_data[ticker] = data\n",
        "        print(f\"Data for {ticker} fetched successfully.\")\n",
        "    else:\n",
        "        print(f\"Failed to fetch data for {ticker}.\")\n",
        "\n",
        "    time.sleep(13)\n",
        "\n",
        "\n",
        "for ticker, data in all_data.items():\n",
        "    data.to_csv(f\"{ticker}_intraday_data.csv\")\n",
        "    print(f\"Saved intraday data for {ticker} to CSV.\")\n",
        "\n",
        "print(\"\\nLast intraday closing prices:\")\n",
        "for ticker, data in all_data.items():\n",
        "    last_close = float(data.iloc[-1]['close'] if 'close' in data.columns else data.iloc[-1]['4. close'])\n",
        "    print(f\"{ticker}: {last_close}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c7ed8c-ff9b-447a-8e81-768dfc018e51",
      "metadata": {
        "id": "e0c7ed8c-ff9b-447a-8e81-768dfc018e51"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "5. To enhance the visual side of our project, we will use the Wikipedia API to retrieve descriptions of the selected tickers.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7441fd5e-f711-44d1-920e-df33cec9e2b9",
      "metadata": {
        "id": "7441fd5e-f711-44d1-920e-df33cec9e2b9"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import wikipedia\n",
        "import pandas as pd\n",
        "from wikipedia.exceptions import DisambiguationError, PageError\n",
        "\n",
        "def get_wikipedia_description(ticker: str, sentences: int = 2):\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    if not isinstance(info, dict) or not info:\n",
        "        return None\n",
        "\n",
        "    company_name = info.get(\"longName\") or info.get(\"shortName\")\n",
        "    if not company_name:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        search_results = wikipedia.search(company_name)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    if not search_results:\n",
        "        return None\n",
        "\n",
        "    page_title = search_results[0]\n",
        "    try:\n",
        "        return wikipedia.summary(page_title, sentences=sentences)\n",
        "    except (DisambiguationError, PageError, Exception):\n",
        "        return None\n",
        "\n",
        "tickers_df = pd.read_csv('top_10_stocks.csv')\n",
        "tickers = tickers_df['Ticker'].tolist()\n",
        "\n",
        "for ticker in tickers:\n",
        "    desc = get_wikipedia_description(ticker)\n",
        "    print(f\"{ticker}: {desc or 'No description available.'}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3ca4fa-131f-4e24-92f1-c92d950b0547",
      "metadata": {
        "id": "7b3ca4fa-131f-4e24-92f1-c92d950b0547"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "âœ… We have now completed the data fetching phase. All further data-related work will be based on this structure, and we can simply adjust the date ranges if needed. Let's now move on to algorithmic trading!\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5a79c79-6f3c-45a2-a03a-d19085893933",
      "metadata": {
        "id": "d5a79c79-6f3c-45a2-a03a-d19085893933"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "6. We now move on to algorithmic trading using the following strategies: Momentum Volatility Strategy, RSI Strategy, and Moving Average Crossover Strategy And of course we are going to Back test it, we will compare them to the Basic : Buy and Hold Strategy.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86cc7f0-0086-4521-9efa-34869cbb7b56",
      "metadata": {
        "id": "c86cc7f0-0086-4521-9efa-34869cbb7b56"
      },
      "outputs": [],
      "source": [
        "def moving_average_crossover_strategy(data, short_window=50, long_window=200):\n",
        "    \"\"\"\n",
        "    Generates trading signals based on Moving Average Crossover\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): DataFrame containing price data\n",
        "        short_window (int): Short-term moving average window\n",
        "        long_window (int): Long-term moving average window\n",
        "\n",
        "    Returns:\n",
        "        pandas.Series: Series of trading signals (1 for buy, -1 for sell, 0 for hold)\n",
        "    \"\"\"\n",
        "    if data is None or data.empty:\n",
        "        return None\n",
        "\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        close_prices = data['Close'].iloc[:, 0]\n",
        "    else:\n",
        "        close_prices = data['Close'] if 'Close' in data.columns else data\n",
        "\n",
        "    short_ma = close_prices.rolling(window=short_window).mean()\n",
        "    long_ma = close_prices.rolling(window=long_window).mean()\n",
        "\n",
        "    signals = pd.Series(0, index=close_prices.index)\n",
        "    signals[short_ma > long_ma] = 1.0\n",
        "    signals[short_ma < long_ma] = -1.0\n",
        "    signals.iloc[:long_window] = 0.0\n",
        "\n",
        "    return signals\n",
        "\n",
        "def rsi_strategy(data, window=14, oversold=30, overbought=70):\n",
        "    \"\"\"\n",
        "    Generates trading signals based on Relative Strength Index (RSI)\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): DataFrame containing price data\n",
        "        window (int): RSI calculation window\n",
        "        oversold (int): Oversold threshold\n",
        "        overbought (int): Overbought threshold\n",
        "\n",
        "    Returns:\n",
        "        pandas.Series: Series of trading signals (1 for buy, -1 for sell, 0 for hold)\n",
        "    \"\"\"\n",
        "    if data is None or data.empty:\n",
        "        return None\n",
        "\n",
        "    # Extract close prices\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        close_prices = data['Close'].iloc[:, 0]  # First ticker\n",
        "    else:\n",
        "        close_prices = data['Close'] if 'Close' in data.columns else data\n",
        "\n",
        "    delta = close_prices.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "    avg_gain = gain.rolling(window=window).mean()\n",
        "    avg_loss = loss.rolling(window=window).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    signals = pd.Series(0, index=close_prices.index)\n",
        "    signals[rsi < oversold] = 1.0  # Buy when oversold\n",
        "    signals[rsi > overbought] = -1.0  # Sell when overbought\n",
        "\n",
        "    signals.iloc[:window] = 0.0\n",
        "\n",
        "    return signals\n",
        "\n",
        "def momentum_volatility_strategy(data, roc_window=126, vol_window=20, roc_threshold=0.05, vol_percentile=75):\n",
        "    \"\"\"\n",
        "    Generates trading signals based on momentum and volatility filters\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): DataFrame containing price data\n",
        "        roc_window (int): Period for Rate of Change calculation\n",
        "        vol_window (int): Period for volatility calculation\n",
        "        roc_threshold (float): Threshold for Rate of Change to trigger signals\n",
        "        vol_percentile (int): Percentile of volatility to use as filter\n",
        "\n",
        "    Returns:\n",
        "        pandas.Series: Series of trading signals (1 for buy, -1 for sell, 0 for hold)\n",
        "    \"\"\"\n",
        "    if data is None or data.empty:\n",
        "        return None\n",
        "\n",
        "    df = data.copy()\n",
        "\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        close_prices = df['Close'].iloc[:, 0]  # First ticker\n",
        "        high_prices = df['High'].iloc[:, 0]\n",
        "        low_prices = df['Low'].iloc[:, 0]\n",
        "    else:\n",
        "        close_prices = df['Close'] if 'Close' in df.columns else df\n",
        "        high_prices = df['High'] if 'High' in df.columns else close_prices\n",
        "        low_prices = df['Low'] if 'Low' in df.columns else close_prices\n",
        "\n",
        "    roc = close_prices.pct_change(periods=roc_window)\n",
        "\n",
        "    high_low = high_prices - low_prices\n",
        "    high_close = abs(high_prices - close_prices.shift(1))\n",
        "    low_close = abs(low_prices - close_prices.shift(1))\n",
        "    tr = pd.DataFrame({'high_low': high_low, 'high_close': high_close, 'low_close': low_close}).max(axis=1)\n",
        "    atr = tr.rolling(window=vol_window).mean()\n",
        "    volatility = atr / close_prices\n",
        "\n",
        "    vol_threshold = volatility.quantile(vol_percentile / 100)\n",
        "\n",
        "    signals = pd.Series(0.0, index=df.index)\n",
        "\n",
        "    for i in range(max(roc_window, vol_window), len(df)):\n",
        "        idx = df.index[i]\n",
        "        roc_val = roc.iloc[i]\n",
        "        vol_val = volatility.iloc[i]\n",
        "\n",
        "        if vol_val <= vol_threshold:\n",
        "            if roc_val > roc_threshold:\n",
        "                signals.iloc[i] = 1.0  # Long\n",
        "            elif roc_val < -roc_threshold:\n",
        "                signals.iloc[i] = -1.0  # Short\n",
        "\n",
        "    return signals\n",
        "\n",
        "def backtest_strategy(data, signals, initial_capital=10000.0, position_size=1.0):\n",
        "    \"\"\"\n",
        "    Backtests a trading strategy based on generated signals\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): DataFrame containing price data\n",
        "        signals (pandas.Series): Series of trading signals\n",
        "        initial_capital (float): Initial capital for the backtest\n",
        "        position_size (float): Position size as a fraction of capital\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing backtest results\n",
        "    \"\"\"\n",
        "    if data is None or data.empty or signals is None:\n",
        "        return None\n",
        "\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        close_prices = data['Close'].iloc[:, 0]  # First ticker\n",
        "    else:\n",
        "        close_prices = data['Close'] if 'Close' in data.columns else data\n",
        "\n",
        "    backtest = pd.DataFrame(index=signals.index)\n",
        "    backtest['price'] = close_prices\n",
        "    backtest['signal'] = signals\n",
        "\n",
        "    backtest['returns'] = backtest['price'].pct_change()\n",
        "\n",
        "    backtest['strategy_returns'] = backtest['signal'].shift(1) * backtest['returns']\n",
        "\n",
        "    backtest['equity_curve'] = (1 + backtest['strategy_returns']).cumprod() * initial_capital\n",
        "\n",
        "    backtest['buy_hold_equity'] = (1 + backtest['returns']).cumprod() * initial_capital\n",
        "\n",
        "    total_return = (backtest['equity_curve'].iloc[-1] / initial_capital - 1) * 100\n",
        "    buy_hold_return = (backtest['buy_hold_equity'].iloc[-1] / initial_capital - 1) * 100\n",
        "\n",
        "    sharpe_ratio = backtest['strategy_returns'].mean() / backtest['strategy_returns'].std() * np.sqrt(252) if backtest['strategy_returns'].std() > 0 else 0\n",
        "    max_drawdown = (backtest['equity_curve'] / backtest['equity_curve'].cummax() - 1).min()\n",
        "\n",
        "    backtest['position_change'] = backtest['signal'].diff()\n",
        "\n",
        "    buys = backtest[backtest['position_change'] > 0].copy()\n",
        "    sells = backtest[backtest['position_change'] < 0].copy()\n",
        "\n",
        "    trades = pd.DataFrame({\n",
        "        'date': list(buys.index) + list(sells.index),\n",
        "        'price': list(buys['price']) + list(sells['price']),\n",
        "        'type': ['buy'] * len(buys) + ['sell'] * len(sells)\n",
        "    })\n",
        "\n",
        "    trades = trades.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    results = {\n",
        "        'equity_curve': backtest['equity_curve'],\n",
        "        'buy_hold_equity': backtest['buy_hold_equity'],\n",
        "        'total_return': total_return,\n",
        "        'buy_hold_return': buy_hold_return,\n",
        "        'sharpe_ratio': sharpe_ratio,\n",
        "        'max_drawdown': max_drawdown,\n",
        "        'trades': trades\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19542bc6-0aad-491d-a986-72bf893812ff",
      "metadata": {
        "id": "19542bc6-0aad-491d-a986-72bf893812ff"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "7. Next, we will handle sentiment analysis and develop strategies based on the sentiment data We will compare that with the basic : Buy and Hold strategy.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1034ead3-6765-482e-8350-163b8dee7800",
      "metadata": {
        "id": "1034ead3-6765-482e-8350-163b8dee7800"
      },
      "outputs": [],
      "source": [
        "def calculate_sentiment(text):\n",
        "    \"\"\"\n",
        "    Calculates sentiment score for text using TextBlob\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to analyze\n",
        "\n",
        "    Returns:\n",
        "        tuple: (polarity score, sentiment label)\n",
        "    \"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity > 0.1:\n",
        "        sentiment = 'POSITIVE'\n",
        "    elif polarity < -0.1:\n",
        "        sentiment = 'NEGATIVE'\n",
        "    else:\n",
        "        sentiment = 'NEUTRAL'\n",
        "\n",
        "    return polarity, sentiment\n",
        "\n",
        "def get_market_sentiment(query='finance stock market'):\n",
        "    \"\"\"\n",
        "    Get overall market sentiment from recent news\n",
        "\n",
        "    Args:\n",
        "        query (str): Query string for news search\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing sentiment analysis results\n",
        "    \"\"\"\n",
        "    gnews = GNews(language='en', country='US', period='1d')\n",
        "\n",
        "    try:\n",
        "        news_results = gnews.get_news(query)\n",
        "\n",
        "        if not news_results:\n",
        "            return {\n",
        "                'positive': 0,\n",
        "                'negative': 0,\n",
        "                'neutral': 0,\n",
        "                'articles': [],\n",
        "                'overall': 'NEUTRAL'\n",
        "            }\n",
        "\n",
        "        positive, negative, neutral = 0, 0, 0\n",
        "        analyzed_articles = []\n",
        "\n",
        "        for article in news_results:\n",
        "            title = article['title']\n",
        "            polarity, sentiment_label = calculate_sentiment(title)\n",
        "\n",
        "            if sentiment_label == 'POSITIVE':\n",
        "                positive += 1\n",
        "            elif sentiment_label == 'NEGATIVE':\n",
        "                negative += 1\n",
        "            else:\n",
        "                neutral += 1\n",
        "\n",
        "            published_date = article.get('published date', '')\n",
        "            try:\n",
        "                date_obj = datetime.strptime(published_date, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "                formatted_date = date_obj.strftime('%Y-%m-%d %H:%M')\n",
        "            except (ValueError, TypeError):\n",
        "                formatted_date = published_date\n",
        "\n",
        "            analyzed_articles.append({\n",
        "                'title': title,\n",
        "                'publisher': article.get('publisher', {}).get('title', 'Unknown'),\n",
        "                'published_date': formatted_date,\n",
        "                'url': article.get('url', ''),\n",
        "                'polarity': polarity,\n",
        "                'sentiment': sentiment_label\n",
        "            })\n",
        "\n",
        "        overall = 'NEUTRAL'\n",
        "        if neutral > (positive + negative):\n",
        "            overall = 'NEUTRAL'\n",
        "        elif positive > negative:\n",
        "            overall = 'POSITIVE'\n",
        "        elif negative > positive:\n",
        "            overall = 'NEGATIVE'\n",
        "\n",
        "        return {\n",
        "            'positive': positive,\n",
        "            'negative': negative,\n",
        "            'neutral': neutral,\n",
        "            'articles': analyzed_articles,\n",
        "            'overall': overall\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in sentiment analysis: {e}\")\n",
        "        return {\n",
        "            'positive': 0,\n",
        "            'negative': 0,\n",
        "            'neutral': 0,\n",
        "            'articles': [],\n",
        "            'overall': 'ERROR',\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "def get_stock_sentiment(ticker, company_name=None):\n",
        "    \"\"\"\n",
        "    Get sentiment specific to a stock/company\n",
        "\n",
        "    Args:\n",
        "        ticker (str): Stock ticker\n",
        "        company_name (str, optional): Company name for better news searching\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing sentiment analysis results\n",
        "    \"\"\"\n",
        "    query = f\"{ticker} stock\"\n",
        "    if company_name:\n",
        "        query = f\"{company_name} {ticker} stock\"\n",
        "\n",
        "    return get_market_sentiment(query)\n",
        "\n",
        "def optimize_sentiment_threshold(sentiment_data, price_data, num_thresholds=21):\n",
        "    \"\"\"\n",
        "    Optimize the sentiment threshold to maximize Sharpe ratio\n",
        "\n",
        "    Args:\n",
        "        sentiment_data (pandas.Series): Series of sentiment scores\n",
        "        price_data (pandas.Series): Series of price data\n",
        "        num_thresholds (int): Number of evenly spaced thresholds to test\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with best threshold and corresponding Sharpe ratio\n",
        "    \"\"\"\n",
        "    if sentiment_data is None or price_data is None or len(sentiment_data) < 10:\n",
        "        return {'threshold': 0.1, 'sharpe': 0}\n",
        "\n",
        "    returns = price_data.pct_change().shift(-1)\n",
        "\n",
        "    data = pd.DataFrame({\n",
        "        'sentiment': sentiment_data,\n",
        "        'returns': returns\n",
        "    }).dropna()\n",
        "\n",
        "    if len(data) < 10:\n",
        "        return {'threshold': 0.1, 'sharpe': 0}\n",
        "\n",
        "    min_sentiment = data['sentiment'].min()\n",
        "    max_sentiment = data['sentiment'].max()\n",
        "\n",
        "\n",
        "    best = {'threshold': 0, 'sharpe': -np.inf}\n",
        "\n",
        "    for threshold in np.linspace(min_sentiment, max_sentiment, num_thresholds):\n",
        "        positions = np.where(data['sentiment'] > threshold, 1, -1)\n",
        "\n",
        "        strategy_returns = positions * data['returns']\n",
        "\n",
        "\n",
        "        if len(strategy_returns) > 1 and strategy_returns.std() > 0:\n",
        "            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252)\n",
        "\n",
        "            if sharpe > best['sharpe']:\n",
        "                best = {'threshold': threshold, 'sharpe': sharpe}\n",
        "\n",
        "    return best\n",
        "\n",
        "def apply_sentiment_strategy(sentiment_data, price_data, threshold=None):\n",
        "    \"\"\"\n",
        "    Apply a sentiment-based trading strategy\n",
        "\n",
        "    Args:\n",
        "        sentiment_data (pandas.Series): Series of sentiment scores\n",
        "        price_data (pandas.Series): Series of price data\n",
        "        threshold (float, optional): Sentiment threshold (if None, will be optimized)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with strategy results\n",
        "    \"\"\"\n",
        "    if sentiment_data is None or price_data is None or len(sentiment_data) < 10:\n",
        "        return None\n",
        "\n",
        "    # Calculate returns\n",
        "    returns = price_data.pct_change()\n",
        "    next_day_returns = returns.shift(-1)\n",
        "\n",
        "    data = pd.DataFrame({\n",
        "        'sentiment': sentiment_data,\n",
        "        'returns': returns,\n",
        "        'next_day_returns': next_day_returns\n",
        "    }).dropna()\n",
        "\n",
        "    if len(data) < 10:\n",
        "        return None\n",
        "\n",
        "    if threshold is None:\n",
        "        optimized = optimize_sentiment_threshold(data['sentiment'], price_data)\n",
        "        threshold = optimized['threshold']\n",
        "        optimized_sharpe = optimized['sharpe']\n",
        "    else:\n",
        "        optimized_sharpe = None\n",
        "\n",
        "    # Generate positions based on sentiment\n",
        "    data['position'] = np.sign(data['sentiment'] - threshold)\n",
        "    data['strategy_returns'] = data['position'] * data['next_day_returns']\n",
        "    data['cum_strategy'] = (1 + data['strategy_returns']).cumprod()\n",
        "    data['cum_buy_hold'] = (1 + data['next_day_returns']).cumprod()\n",
        "\n",
        "\n",
        "    correlation = data['sentiment'].corr(data['next_day_returns'])\n",
        "\n",
        "    if len(data) > 1:\n",
        "        sharpe_strategy = data['strategy_returns'].mean() / data['strategy_returns'].std() * np.sqrt(252) if data['strategy_returns'].std() > 0 else 0\n",
        "        sharpe_buy_hold = data['next_day_returns'].mean() / data['next_day_returns'].std() * np.sqrt(252) if data['next_day_returns'].std() > 0 else 0\n",
        "    else:\n",
        "        sharpe_strategy = 0\n",
        "        sharpe_buy_hold = 0\n",
        "\n",
        "    win_rate = (data['strategy_returns'] > 0).mean() * 100\n",
        "\n",
        "    # Final results\n",
        "    results = {\n",
        "        'data': data,\n",
        "        'threshold': threshold,\n",
        "        'optimized_sharpe': optimized_sharpe,\n",
        "        'correlation': correlation,\n",
        "        'sharpe_strategy': sharpe_strategy,\n",
        "        'sharpe_buy_hold': sharpe_buy_hold,\n",
        "        'win_rate': win_rate,\n",
        "        'cum_strategy': data['cum_strategy'],\n",
        "        'cum_buy_hold': data['cum_buy_hold'],\n",
        "        'total_return_strategy': (data['cum_strategy'].iloc[-1] - 1) * 100 if len(data) > 0 else 0,\n",
        "        'total_return_buy_hold': (data['cum_buy_hold'].iloc[-1] - 1) * 100 if len(data) > 0 else 0\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def simulate_sentiment_strategy(stock_sentiment, stock_data, ticker):\n",
        "    \"\"\"\n",
        "    Simulate a sentiment-based trading strategy\n",
        "\n",
        "    Args:\n",
        "        stock_sentiment (dict): Dictionary with stock sentiment analysis results\n",
        "        stock_data (pandas.DataFrame): Stock price data\n",
        "        ticker (str): Stock ticker symbol\n",
        "\n",
        "    Returns:\n",
        "        dict: Strategy simulation results\n",
        "    \"\"\"\n",
        "    sentiment_values = [article['polarity'] for article in stock_sentiment['articles'] if 'polarity' in article]\n",
        "\n",
        "    if not sentiment_values:\n",
        "        return None\n",
        "\n",
        "    if isinstance(stock_data.columns, pd.MultiIndex):\n",
        "        price_data = stock_data.xs(ticker, axis=1, level=1)['Close']\n",
        "    else:\n",
        "        price_data = stock_data['Close']\n",
        "\n",
        "    median_sentiment = np.median(sentiment_values)\n",
        "    dates = price_data.index[-min(len(price_data), 30):]\n",
        "    mock_sentiment = pd.Series(\n",
        "        [median_sentiment + (np.random.random() - 0.5) * 0.2 for _ in range(len(dates))],\n",
        "        index=dates\n",
        "    )\n",
        "\n",
        "    return apply_sentiment_strategy(mock_sentiment, price_data.loc[mock_sentiment.index])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e890e6b-8bb8-4650-af2c-ffc84f6d037a",
      "metadata": {
        "id": "0e890e6b-8bb8-4650-af2c-ffc84f6d037a"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:200%; font-weight:bold;\">\n",
        "Finally, we move on to the plotting section.\n",
        "</p>\n",
        "\n",
        "<p style=\"color:#4B0082; font-size:150%;\">\n",
        "We aimed to visualize most of the key indicators used to build our strategies, as well as the results from those strategies helping us decide which one performs best and how to recalibrate the others.  \n",
        "We also decided to leverage our web scraping and API data to create a brief presentation of each company.  \n",
        "And as you've probably noticed by now from how everything is coded this project is designed for an interactive website focused on the 10 selected tickers! ðŸ˜Š We wonâ€™t spoil everything by listing all the plots itâ€™ll be much more enjoyable to discover them directly on the website, so donâ€™t hesitate to keep exploring\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d614fe0b-5d82-4ea1-accb-a3ae7c3e638c",
      "metadata": {
        "id": "d614fe0b-5d82-4ea1-accb-a3ae7c3e638c"
      },
      "outputs": [],
      "source": [
        " # SECTION 1: COMPANY OVERVIEW\n",
        "    # ---------------------------\n",
        "    st.header(\"Company Overview\")\n",
        "\n",
        "    company_info = results.get('company_info', {})\n",
        "\n",
        "    if company_info:\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "\n",
        "        with col1:\n",
        "            # Company name and description\n",
        "            st.subheader(company_info.get('name', ticker))\n",
        "            st.markdown(f\"**Sector:** {company_info.get('sector', 'N/A')} | **Industry:** {company_info.get('industry', 'N/A')}\")\n",
        "\n",
        "            if company_info.get('description'):\n",
        "                st.markdown(\"### Business Description\")\n",
        "                st.markdown(company_info.get('description'))\n",
        "\n",
        "            if company_info.get('wiki_description'):\n",
        "                st.markdown(\"### From Wikipedia\")\n",
        "                st.markdown(company_info.get('wiki_description'))\n",
        "\n",
        "        with col2:\n",
        "            # Company metrics in a nice card format\n",
        "            st.markdown(\"### Key Metrics\")\n",
        "            metrics_card = f\"\"\"\n",
        "            * **Market Cap:** {company_info.get('market_cap', 'N/A')}\n",
        "            * **P/E Ratio:** {company_info.get('pe_ratio', 'N/A')}\n",
        "            * **Dividend Yield:** {company_info.get('dividend_yield', 'N/A')}\n",
        "            * **52-Week High:** {company_info.get('52_week_high', 'N/A')}\n",
        "            * **52-Week Low:** {company_info.get('52_week_low', 'N/A')}\n",
        "            * **Website:** [{company_info.get('website', 'N/A')}]({company_info.get('website', '#')})\n",
        "            \"\"\"\n",
        "            st.markdown(metrics_card)\n",
        "    else:\n",
        "        st.warning(f\"Company information for {ticker} is not available.\")\n",
        "\n",
        "    # Divider\n",
        "    st.markdown('<div class=\"section-divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # SECTION 2: PRICE ANALYSIS\n",
        "    # -------------------------\n",
        "    st.header(\"Price Analysis\")\n",
        "\n",
        "    stock_data = results.get('stock_data')\n",
        "    metrics_df = results.get('metrics_df')\n",
        "\n",
        "    if stock_data is not None:\n",
        "        # Create price chart\n",
        "        st.subheader(f\"{ticker} Stock Price\")\n",
        "        price_chart = plot_price_chart(stock_data, ticker)\n",
        "        st.plotly_chart(price_chart, use_container_width=True)\n",
        "\n",
        "        # Stock vs Index comparison\n",
        "        st.subheader(f\"{ticker} vs. Dow Jones Index\")\n",
        "\n",
        "        # Get Dow Jones data for the same period\n",
        "        start_date = stock_data.index[0].strftime('%Y-%m-%d')\n",
        "        end_date = stock_data.index[-1].strftime('%Y-%m-%d')\n",
        "        try:\n",
        "            dow_data = get_historical_data([\"^DJI\"], start_date, end_date)\n",
        "            comparison_chart = plot_stock_vs_index(stock_data, ticker, dow_data)\n",
        "            if comparison_chart:\n",
        "                st.plotly_chart(comparison_chart, use_container_width=True)\n",
        "            else:\n",
        "                st.info(\"Could not create comparison chart with Dow Jones Index.\")\n",
        "        except Exception as e:\n",
        "            st.info(f\"Could not fetch Dow Jones data for comparison: {e}\")\n",
        "\n",
        "        # Metrics table if available\n",
        "        if metrics_df is not None and ticker in metrics_df.index:\n",
        "            st.subheader(\"Performance Metrics\")\n",
        "            ticker_metrics = metrics_df.loc[[ticker]]\n",
        "            st.dataframe(ticker_metrics, use_container_width=True)\n",
        "\n",
        "            # Create a bar chart of returns\n",
        "            return_cols = [col for col in ticker_metrics.columns if 'Return' in col]\n",
        "            if return_cols:\n",
        "                returns_data = ticker_metrics[return_cols].T\n",
        "                returns_data.columns = ['Value']\n",
        "\n",
        "                fig = go.Figure()\n",
        "                colors = ['#27AE60' if x >= 0 else '#E74C3C' for x in returns_data['Value']]\n",
        "\n",
        "                fig.add_trace(go.Bar(\n",
        "                    x=returns_data.index,\n",
        "                    y=returns_data['Value'],\n",
        "                    marker_color=colors\n",
        "                ))\n",
        "\n",
        "                fig.update_layout(\n",
        "                    title=f\"{ticker} Returns\",\n",
        "                    xaxis_title=\"Time Period\",\n",
        "                    yaxis_title=\"Return (%)\",\n",
        "                    template='plotly_white',\n",
        "                    height=400,\n",
        "                    margin=dict(l=20, r=20, t=50, b=20)\n",
        "                )\n",
        "\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "    else:\n",
        "        st.warning(f\"Stock price data for {ticker} is not available for the selected date range.\")\n",
        "\n",
        "    # Divider\n",
        "    st.markdown('<div class=\"section-divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # SECTION 3: TRADING STRATEGIES\n",
        "    # -----------------------------\n",
        "    st.header(\"Trading Strategies Analysis\")\n",
        "\n",
        "    # Show results for each strategy\n",
        "    strategies = [\n",
        "        ('Moving Average Crossover', 'ma_strategy_results', 'Strategy crossing short and long moving averages'),\n",
        "        ('RSI Strategy', 'rsi_strategy_results', 'Strategy based on Relative Strength Index overbought/oversold conditions'),\n",
        "        ('Momentum Volatility Strategy', 'mom_vol_strategy_results', 'Strategy combining momentum indicators with volatility filters')\n",
        "    ]\n",
        "\n",
        "    for strategy_name, results_key, description in strategies:\n",
        "        st.subheader(strategy_name)\n",
        "        st.markdown(description)\n",
        "\n",
        "        strategy_results = results.get(results_key)\n",
        "        if strategy_results is not None:\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                # Strategy metrics\n",
        "                total_return = strategy_results.get('total_return', 0)\n",
        "                buy_hold_return = strategy_results.get('buy_hold_return', 0)\n",
        "\n",
        "                st.metric(\n",
        "                    label=\"Strategy Return\",\n",
        "                    value=f\"{total_return:.2f}%\",\n",
        "                    delta=f\"{total_return - buy_hold_return:.2f}% vs Buy & Hold\"\n",
        "                )\n",
        "\n",
        "                st.metric(\n",
        "                    label=\"Buy & Hold Return\",\n",
        "                    value=f\"{buy_hold_return:.2f}%\"\n",
        "                )\n",
        "\n",
        "                st.metric(\n",
        "                    label=\"Sharpe Ratio\",\n",
        "                    value=f\"{strategy_results.get('sharpe_ratio', 0):.2f}\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                # Strategy performance chart\n",
        "                equity_chart = plot_strategy_performance(strategy_results)\n",
        "                st.plotly_chart(equity_chart, use_container_width=True)\n",
        "        else:\n",
        "            st.warning(f\"{strategy_name} results are not available.\")\n",
        "\n",
        "    # Divider\n",
        "    st.markdown('<div class=\"section-divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # SECTION 4: SENTIMENT ANALYSIS\n",
        "    # ----------------------------\n",
        "    st.header(\"Sentiment Analysis\")\n",
        "\n",
        "    # 4.1 Market Sentiment\n",
        "    st.subheader(\"Market Sentiment\")\n",
        "    market_sentiment = results.get('market_sentiment')\n",
        "\n",
        "    if market_sentiment:\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # Sentiment metrics\n",
        "            st.metric(\"Positive News\", market_sentiment.get('positive', 0))\n",
        "            st.metric(\"Negative News\", market_sentiment.get('negative', 0))\n",
        "            st.metric(\"Neutral News\", market_sentiment.get('neutral', 0))\n",
        "            st.markdown(f\"**Overall Market Sentiment:** {market_sentiment.get('overall', 'NEUTRAL')}\")\n",
        "\n",
        "        with col2:\n",
        "            # Sentiment pie chart\n",
        "            sentiment_pie = plot_sentiment_pie(\n",
        "                market_sentiment.get('positive', 0),\n",
        "                market_sentiment.get('negative', 0),\n",
        "                market_sentiment.get('neutral', 0)\n",
        "            )\n",
        "            st.plotly_chart(sentiment_pie, use_container_width=True)\n",
        "\n",
        "        # Recent market news\n",
        "        st.markdown(\"### Recent Market News\")\n",
        "        if 'articles' in market_sentiment and market_sentiment['articles']:\n",
        "            for article in market_sentiment['articles'][:5]:  # Limit to 5 articles\n",
        "                with st.expander(article['title']):\n",
        "                    st.markdown(f\"**Publisher:** {article.get('publisher', 'Unknown')}\")\n",
        "                    st.markdown(f\"**Published:** {article.get('published_date', 'Unknown')}\")\n",
        "                    st.markdown(f\"**Sentiment:** {article.get('sentiment', 'NEUTRAL')} (Score: {article.get('polarity', 0):.2f})\")\n",
        "                    st.markdown(f\"[Read article]({article.get('url', '#')})\")\n",
        "        else:\n",
        "            st.info(\"No market news articles found.\")\n",
        "    else:\n",
        "        st.warning(\"Market sentiment analysis is not available.\")\n",
        "\n",
        "    # 4.2 Stock-specific Sentiment\n",
        "    st.subheader(f\"{ticker} Sentiment Analysis\")\n",
        "    stock_sentiment = results.get('stock_sentiment')\n",
        "\n",
        "    if stock_sentiment:\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # Sentiment metrics\n",
        "            st.metric(\"Positive News\", stock_sentiment.get('positive', 0))\n",
        "            st.metric(\"Negative News\", stock_sentiment.get('negative', 0))\n",
        "            st.metric(\"Neutral News\", stock_sentiment.get('neutral', 0))\n",
        "            st.markdown(f\"**Overall {ticker} Sentiment:** {stock_sentiment.get('overall', 'NEUTRAL')}\")\n",
        "\n",
        "        with col2:\n",
        "            # Sentiment pie chart\n",
        "            sentiment_pie = plot_sentiment_pie(\n",
        "                stock_sentiment.get('positive', 0),\n",
        "                stock_sentiment.get('negative', 0),\n",
        "                stock_sentiment.get('neutral', 0)\n",
        "            )\n",
        "            st.plotly_chart(sentiment_pie, use_container_width=True)\n",
        "\n",
        "        # Recent stock news\n",
        "        st.markdown(f\"### Recent {ticker} News\")\n",
        "        if 'articles' in stock_sentiment and stock_sentiment['articles']:\n",
        "            for article in stock_sentiment['articles'][:5]:  # Limit to 5 articles\n",
        "                with st.expander(article['title']):\n",
        "                    st.markdown(f\"**Publisher:** {article.get('publisher', 'Unknown')}\")\n",
        "                    st.markdown(f\"**Published:** {article.get('published_date', 'Unknown')}\")\n",
        "                    st.markdown(f\"**Sentiment:** {article.get('sentiment', 'NEUTRAL')} (Score: {article.get('polarity', 0):.2f})\")\n",
        "                    st.markdown(f\"[Read article]({article.get('url', '#')})\")\n",
        "        else:\n",
        "            st.info(f\"No news articles found for {ticker}.\")\n",
        "\n",
        "        # 4.3 Sentiment-based Trading Strategy (if available)\n",
        "        sentiment_strategy_results = results.get('sentiment_strategy_results')\n",
        "\n",
        "        if sentiment_strategy_results:\n",
        "            st.subheader(\"Sentiment-Based Trading Strategy\")\n",
        "            st.markdown(\"\"\"\n",
        "            This strategy uses news sentiment to make trading decisions:\n",
        "            - Long position when sentiment is positive (above threshold)\n",
        "            - Short position when sentiment is negative (below threshold)\n",
        "            \"\"\")\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Strategy Return\",\n",
        "                    value=f\"{sentiment_strategy_results.get('total_return_strategy', 0):.2f}%\",\n",
        "                    delta=f\"{sentiment_strategy_results.get('total_return_strategy', 0) - sentiment_strategy_results.get('total_return_buy_hold', 0):.2f}% vs Buy & Hold\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Buy & Hold Return\",\n",
        "                    value=f\"{sentiment_strategy_results.get('total_return_buy_hold', 0):.2f}%\"\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                st.metric(\n",
        "                    label=\"Win Rate\",\n",
        "                    value=f\"{sentiment_strategy_results.get('win_rate', 0):.2f}%\"\n",
        "                )\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Strategy Sharpe Ratio\",\n",
        "                    value=f\"{sentiment_strategy_results.get('sharpe_strategy', 0):.2f}\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Sentiment-Return Correlation\",\n",
        "                    value=f\"{sentiment_strategy_results.get('correlation', 0):.4f}\"\n",
        "                )\n",
        "\n",
        "            # Plot cumulative returns if available\n",
        "            if 'cum_strategy' in sentiment_strategy_results and 'cum_buy_hold' in sentiment_strategy_results:\n",
        "                st.subheader(\"Cumulative Returns\")\n",
        "\n",
        "                fig = go.Figure()\n",
        "\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=sentiment_strategy_results['cum_strategy'].index,\n",
        "                    y=sentiment_strategy_results['cum_strategy'],\n",
        "                    mode='lines',\n",
        "                    name='Sentiment Strategy',\n",
        "                    line=dict(color='#27AE60', width=2)\n",
        "                ))\n",
        "\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=sentiment_strategy_results['cum_buy_hold'].index,\n",
        "                    y=sentiment_strategy_results['cum_buy_hold'],\n",
        "                    mode='lines',\n",
        "                    name='Buy & Hold',\n",
        "                    line=dict(color='#2C3E50', width=2)\n",
        "                ))\n",
        "\n",
        "                fig.update_layout(\n",
        "                    title=f\"Sentiment Strategy vs Buy & Hold ({ticker})\",\n",
        "                    xaxis_title=\"Date\",\n",
        "                    yaxis_title=\"Growth of $1 Investment\",\n",
        "                    template='plotly_white',\n",
        "                    height=400,\n",
        "                    legend=dict(\n",
        "                        orientation=\"h\",\n",
        "                        yanchor=\"bottom\",\n",
        "                        y=1.02,\n",
        "                        xanchor=\"right\",\n",
        "                        x=1\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                # Add information about the sentiment threshold\n",
        "                st.info(f\"Optimized sentiment threshold: {sentiment_strategy_results.get('threshold', 0):.4f}\")\n",
        "    else:\n",
        "        st.warning(f\"Sentiment analysis for {ticker} is not available.\")\n",
        "\n",
        "    # Divider\n",
        "    st.markdown('<div class=\"section-divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # SECTION 5: ADVANCED VISUALIZATIONS\n",
        "    # ----------------------------------\n",
        "    st.header(\"Advanced Data Visualizations\")\n",
        "\n",
        "    # Get the data for visualizations\n",
        "    if stock_data is not None:\n",
        "        # Extract close prices\n",
        "        if isinstance(stock_data.columns, pd.MultiIndex):\n",
        "            close_prices = stock_data.xs(ticker, axis=1, level=1)['Close']\n",
        "        else:\n",
        "            close_prices = stock_data['Close']\n",
        "\n",
        "        # 5.1 Return Distribution Analysis\n",
        "        st.subheader(\"Return Distribution Analysis\")\n",
        "\n",
        "        # Let user select the return period and aggregation\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            period_options = [\"Daily\", \"Weekly\", \"Monthly\", \"Quarterly\", \"Yearly\"]\n",
        "            selected_period = st.selectbox(\"Select Return Period\", period_options)\n",
        "\n",
        "            period_map = {\n",
        "                \"Daily\": 1,\n",
        "                \"Weekly\": 5,\n",
        "                \"Monthly\": 21,\n",
        "                \"Quarterly\": 63,\n",
        "                \"Yearly\": 252\n",
        "            }\n",
        "            period_days = period_map.get(selected_period, 1)\n",
        "\n",
        "        with col2:\n",
        "            display_options = [\"Histogram\", \"Box Plot\", \"Monthly Heatmap\"]\n",
        "            display_type = st.selectbox(\"Select Visualization Type\", display_options)\n",
        "\n",
        "        # Calculate returns for the selected period\n",
        "        returns = calculate_returns_for_period(close_prices, period_days)\n",
        "\n",
        "        if display_type == \"Histogram\":\n",
        "            hist_fig = plot_return_histogram(returns, ticker, selected_period)\n",
        "            st.plotly_chart(hist_fig, use_container_width=True)\n",
        "\n",
        "        elif display_type == \"Box Plot\":\n",
        "            box_fig = plot_return_boxplot(returns, ticker)\n",
        "            st.plotly_chart(box_fig, use_container_width=True)\n",
        "\n",
        "        elif display_type == \"Monthly Heatmap\":\n",
        "            heatmap_fig = plot_monthly_returns_heatmap(close_prices, ticker)\n",
        "            st.plotly_chart(heatmap_fig, use_container_width=True)\n",
        "\n",
        "        # 5.2 Volatility Analysis\n",
        "        st.subheader(\"Volatility Analysis\")\n",
        "\n",
        "        # Calculate rolling volatility\n",
        "        if len(close_prices) > 21:  # Need at least some data for volatility calculation\n",
        "            volatility_fig = plot_rolling_volatility(close_prices, ticker)\n",
        "            st.plotly_chart(volatility_fig, use_container_width=True)\n",
        "        else:\n",
        "            st.warning(\"Not enough data to calculate volatility.\")\n",
        "\n",
        "# Monte Carlo Process\n",
        "\n",
        "# Verifying the fetched data\n",
        "if data.empty:\n",
        "    raise ValueError(\"No data retrieved. Check your connection or the symbol.\")\n",
        "\n",
        "# Extracting adjusted closing prices\n",
        "prices = data[\"Close\"].resample('YE').last().values\n",
        "\n",
        "# Extracting years by explicitly converting index to datetime\n",
        "years = [date.year for date in data.resample('YE').last().index]\n",
        "\n",
        "# Checking if data covers at least 2 years (2019â€“2023 ideally)\n",
        "if len(prices) < 2:\n",
        "    raise ValueError(\"Insufficient data for simulation. At least 2 years of data are required.\")\n",
        "\n",
        "# Calculating historical returns\n",
        "log_returns = np.log(prices[1:] / prices[:-1])  # Log returns\n",
        "mean_return = log_returns.mean()\n",
        "volatility = log_returns.std()\n",
        "\n",
        "# Manual adjustment (if needed)\n",
        "volatility_adjusted = max(volatility, 0.15)       # Set a realistic minimum volatility at 15%\n",
        "mean_return_adjusted = min(mean_return, 0.1)      # Cap the average return at 10%\n",
        "\n",
        "# Forecasting with ETS\n",
        "model = ExponentialSmoothing(prices, trend='add', seasonal=None).fit()\n",
        "forecast = model.forecast(5)  # Forecast for 5 periods (2025â€“2029)\n",
        "\n",
        "# Forecast adjustment (cap growth)\n",
        "forecast = np.clip(forecast, None, prices[-1] * 1.5)  # No more than 50% growth over the period\n",
        "\n",
        "# Monte Carlo simulation\n",
        "np.random.seed(42)\n",
        "simulations = 500\n",
        "forecast_years = len(forecast)\n",
        "price_paths = np.zeros((simulations, forecast_years))\n",
        "\n",
        "# Use the real 2024 price as the starting point for all paths\n",
        "initial_price_2024 = prices[-1]\n",
        "\n",
        "for i in range(simulations):\n",
        "    price = initial_price_2024\n",
        "    for t in range(forecast_years):\n",
        "        if t == 0:\n",
        "            price = initial_price_2024\n",
        "        else:\n",
        "            forecasted_price = forecast[t - 1]\n",
        "            random_return = np.random.normal(mean_return_adjusted, volatility_adjusted)\n",
        "            price = forecasted_price * (1 + random_return)\n",
        "        price_paths[i, t] = price\n",
        "\n",
        "# Monte Carlo statistics\n",
        "mean_mc = price_paths.mean(axis=0)  # Average path\n",
        "std_mc = price_paths.std(axis=0)    # Standard deviation\n",
        "\n",
        "# Compare average paths to ETS forecast\n",
        "above_forecast = np.sum(mean_mc > forecast)\n",
        "below_forecast = np.sum(mean_mc < forecast)\n",
        "\n",
        "# Recommendation decision\n",
        "if above_forecast > below_forecast:\n",
        "    recommendation = \"Buy\"\n",
        "elif below_forecast > above_forecast:\n",
        "    recommendation = \"Sell\"\n",
        "else:\n",
        "    recommendation = \"Hold\"\n",
        "\n",
        "# Trend annotation for the plot\n",
        "if above_forecast > below_forecast:\n",
        "    trend_text = f\"More paths above the forecast (above: {above_forecast}, below: {below_forecast})\"\n",
        "else:\n",
        "    trend_text = f\"More paths below the forecast (above: {above_forecast}, below: {below_forecast})\"\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(price_paths.T, color='purple', alpha=0.1)  # Monte Carlo paths\n",
        "plt.plot(range(forecast_years), forecast, color='red', label='ETS Forecast (adjusted)', linewidth=2)\n",
        "\n",
        "# Set x-axis to display future years (2025â€“2029)\n",
        "plt.xticks(ticks=range(forecast_years), labels=[str(2025 + i) for i in range(forecast_years)])\n",
        "\n",
        "# Annotate the general trend of the paths\n",
        "plt.annotate(trend_text, xy=(0.5, 0.9), xycoords='axes fraction', fontsize=12, ha='center', color='green')\n",
        "\n",
        "# Annotate the recommendation\n",
        "plt.annotate(f\"Recommendation: {recommendation}\", xy=(0.5, 0.85), xycoords='axes fraction', fontsize=12, ha='center', color='blue')\n",
        "\n",
        "plt.title('Monte Carlo Simulation with ETS Forecast')\n",
        "plt.xlabel('Future Years')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Creating a DataFrame for forecast results\n",
        "forecast_years_list = [2025 + i for i in range(forecast_years)]\n",
        "forecast_df = pd.DataFrame({\n",
        "    'Year': forecast_years_list,\n",
        "    'Price Forecast': forecast,\n",
        "    'Monte Carlo Mean Path': mean_mc,\n",
        "    'Monte Carlo Std Dev': std_mc,\n",
        "    'Recommendation': recommendation\n",
        "})\n",
        "\n",
        "print(forecast_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f3c164-1e10-4ac6-9143-e1213a5b79e1",
      "metadata": {
        "id": "d2f3c164-1e10-4ac6-9143-e1213a5b79e1"
      },
      "source": [
        "<p style=\"color:#4B0082; font-size:150%; font-weight:bold;\">\n",
        "You will now see what the website looks like.  \n",
        "We aimed to build an interactive platform that allows investors to understand which strategies work best for this type of asset but most importantly, to stay informed.  \n",
        "Technical analysis is powerful, but it means little without fundamental analysis, which includes news, company background, and more.  \n",
        "We hope this project meets your expectations. Thank you for everything! ðŸ˜Š\n",
        "</p>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
